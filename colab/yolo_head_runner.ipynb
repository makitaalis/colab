{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OrangePi_passangers — YOLOv8 head training (Colab)\n",
        "\n",
        "Этот ноутбук запускает обучение через **скрипты проекта** (а не через отдельный `train.py`).\n",
        "\n",
        "Runbook (подробнее): `Docs/Проект/Операции/ML - Дообучение YOLOv8 head (Google Colab).md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EDIT ME ===\n",
        "GITHUB_REPO = 'https://github.com/<USER_OR_ORG>/OrangePi_passangers.git'\n",
        "BRANCH = 'main'\n",
        "\n",
        "# Drive layout (persistent)\n",
        "DRIVE_BASE = '/content/drive/MyDrive/OrangePi_passangers_ml'\n",
        "# Dataset in Drive: either a folder OR a packed archive.\n",
        "# Option A (folder): upload dataset tree to this path.\n",
        "DATASET_DRIVE_DIR = f\"{DRIVE_BASE}/datasets/brainwash.v1i.yolov8\"  # <-- поменяй\n",
        "# Option B (archive): pack locally (tar -czf ...) and upload archive to Drive.\n",
        "DATASET_DRIVE_ARCHIVE = f\"{DRIVE_BASE}/datasets_archives/brainwash.v1i.yolov8.tgz\"  # <-- поменяй\n",
        "\n",
        "# Local (Colab runtime) dataset location (fast I/O)\n",
        "DATASET_ROOT = '/content/datasets/brainwash.v1i.yolov8'\n",
        "ARTIFACTS_ROOT = f\"{DRIVE_BASE}/artifacts/yolov8-head\"\n",
        "\n",
        "# Run params\n",
        "RUN_LABEL = 'smoke_colab_e1_640'\n",
        "IMGSZ = 640\n",
        "EPOCHS = 1\n",
        "WORKERS = 2\n",
        "DEVICE = 0\n",
        "\n",
        "print('DATASET_ROOT (runtime):', DATASET_ROOT)\n",
        "print('DATASET_DRIVE_DIR:', DATASET_DRIVE_DIR)\n",
        "print('DATASET_DRIVE_ARCHIVE:', DATASET_DRIVE_ARCHIVE)\n",
        "print('ARTIFACTS_ROOT:', ARTIFACTS_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!rm -rf OrangePi_passangers\n",
        "!git clone --depth 1 --branch \"$BRANCH\" \"$GITHUB_REPO\" OrangePi_passangers\n",
        "%cd /content/OrangePi_passangers\n",
        "!git rev-parse --short HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare dataset in /content (recommended for speed)\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "dst = Path(DATASET_ROOT)\n",
        "dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if dst.exists():\n",
        "    print('Dataset already present:', dst)\n",
        "else:\n",
        "    arc = Path(DATASET_DRIVE_ARCHIVE)\n",
        "    src_dir = Path(DATASET_DRIVE_DIR)\n",
        "    if arc.exists():\n",
        "        print('Extracting archive from Drive:', arc)\n",
        "        if str(arc).endswith(('.tgz', '.tar.gz')):\n",
        "            cmd = ['tar', '-xzf', str(arc), '-C', str(dst.parent)]\n",
        "        elif str(arc).endswith(('.tar.zst', '.tar.zstd')):\n",
        "            cmd = ['tar', '--zstd', '-xf', str(arc), '-C', str(dst.parent)]\n",
        "        else:\n",
        "            cmd = ['tar', '-xf', str(arc), '-C', str(dst.parent)]\n",
        "        subprocess.check_call(cmd)\n",
        "        # If archive was created as <parent>/brainwash.v1i.yolov8, ensure it landed where we expect\n",
        "        if not dst.exists():\n",
        "            raise RuntimeError(f'Archive extracted but expected dataset dir not found: {dst}. Check archive root folder name.')\n",
        "    elif src_dir.exists():\n",
        "        print('Copying dataset folder from Drive to runtime disk (rsync-like):', src_dir)\n",
        "        shutil.copytree(src_dir, dst, dirs_exist_ok=False)\n",
        "    else:\n",
        "        raise FileNotFoundError('Dataset not found in Drive. Upload either DATASET_DRIVE_DIR folder or DATASET_DRIVE_ARCHIVE file.')\n",
        "\n",
        "print('Dataset ready:', dst)\n",
        "print('Sample:', list((dst/'train'/'images').glob('*'))[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -V\n",
        "!nvidia-smi -L\n",
        "\n",
        "# Project-tested Ultralytics version (repo .venv): 8.4.14\n",
        "!pip -q install ultralytics==8.4.14\n",
        "!python -c \"import torch, ultralytics, numpy as np; print('torch', torch.__version__); print('ultralytics', ultralytics.__version__); print('numpy', np.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Persist artifacts by symlinking project dirs to Drive\n",
        "!mkdir -p \"$ARTIFACTS_ROOT/Docs_auto\" \"$ARTIFACTS_ROOT/runs\"\n",
        "\n",
        "!rm -rf Docs/auto\n",
        "!ln -s \"$ARTIFACTS_ROOT/Docs_auto\" Docs/auto\n",
        "\n",
        "!rm -rf ml/yolov8_head_finetune/runs\n",
        "!mkdir -p ml/yolov8_head_finetune\n",
        "!ln -s \"$ARTIFACTS_ROOT/runs\" ml/yolov8_head_finetune/runs\n",
        "\n",
        "!ls -la Docs | head -n 20\n",
        "!ls -la ml/yolov8_head_finetune | head -n 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write Colab-specific data.yaml (DO NOT use ml/yolov8_head_finetune/data_head.yaml as-is; it has local paths)\n",
        "from pathlib import Path\n",
        "\n",
        "data_yaml = Path(ARTIFACTS_ROOT) / 'data_head_colab.yaml'\n",
        "data_yaml.write_text(\n",
        "    '\\n'.join([\n",
        "        'path: ' + str(Path(DATASET_ROOT)),\n",
        "        'train: train/images',\n",
        "        'val: valid/images',\n",
        "        'test: test/images',\n",
        "        '',\n",
        "        'names:',\n",
        "        '  0: head',\n",
        "        ''\n",
        "    ]),\n",
        "    encoding='utf-8'\n",
        ")\n",
        "print('Wrote:', str(data_yaml))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!bash scripts/yolo_train_run.sh \\\n",
        "  --name \"$RUN_LABEL\" \\\n",
        "  --dataset \"$DATASET_ROOT\" \\\n",
        "  --data \"$ARTIFACTS_ROOT/data_head_colab.yaml\" \\\n",
        "  --model ml/yolov8_head_finetune/weights/base/yolov8_head_scut_nano.pt \\\n",
        "  --imgsz \"$IMGSZ\" --epochs \"$EPOCHS\" --batch auto --device \"$DEVICE\" --workers \"$WORKERS\" \\\n",
        "  --execute\n",
        "\n",
        "!echo 'Latest run id:'\n",
        "!cat Docs/auto/ml-training/yolov8-head/_latest.txt"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
