# Сравнение: Luxonis `depth-people-counting` vs текущий `transport-strict` (подсчёт пассажиров IN/OUT)

Цель сравнения: понять, насколько пример Luxonis подходит для **подсчёта пассажиров в дверях общественного транспорта** (IN/OUT), где:

- камера сверху (top‑down), высота ~2.3м, наклон ~20°;
- рабочая ширина двери ~120см;
- часто идут **2–3 человека рядом или “паровозиком”**;
- люди могут **стоять в проёме**, но событие нужно фиксировать **только при факте входа/выхода**;
- важны **минимум ложных** и стабильная работа на edge (OPi Zero 3 + OAK‑D Lite).

## 1) Что делает Luxonis `depth-people-counting` (факт по коду)

Репозиторий: `luxonis/oak-examples` → `neural-networks/counting/depth-people-counting`.

Ключевые компоненты пайплайна:

1. На устройстве:
   - `StereoDepth` строит **disparity** (карта глубины в формате disparity).
   - `ApplyColormap` красит disparity для удобной визуализации.
   - `ObjectTracker` принимает “детекции” и ведёт `tracklets` (ID + ROI).

2. На host (Python‑код, **HostNode**):
   - `DisparityToDetections` берёт disparity‑кадры и делает **простую сегментацию**:
     - порог по диапазону disparity (`threshold_low/high`);
     - морфологическое “opening” (`kernel_size`);
     - поиск контуров.
   - В текущей реализации выбирается **только один контур**: `max(contours, key=cv2.contourArea)`.
     - Итог: **1 “person” detection на кадр максимум** (даже если в кадре 2–3 человека).

3. Подсчёт:
   - `AnnotationNode` считает пересечение **одной линии** (по оси `x` или `y`) на основании движения центроида ROI трека.
   - Нет логики “2 линии + mid + anti‑duplicate + rearm” как в нашем проекте.

Вывод: этот пример **не является “NN people detector”**. Это *depth‑only blob segmentation*, и из коробки рассчитан на сценарий “в кадре по сути один человек/одна группа”.

## 2) Плюсы `depth-people-counting` для транспорта

Потенциальные сильные стороны (если сценарий подходит):

- **Privacy‑friendly**: можно считать без RGB (по disparity), т.е. “без лица”.
- Нетребователен к освещению (в рамках возможностей depth).
- Логика простая, легко экспериментировать с порогами и ROI.

## 3) Минусы `depth-people-counting` именно для вашей задачи

### 3.1. Multi‑person (2–3 рядом) — критический минус

В текущем коде:

- детекция = **1 контур maxArea** → **второй человек игнорируется**;
- при двух рядом, даже если делать “все контуры”, depth‑blob часто **слипается в один контур** (одна “масса”) → всё равно будет 1 детекция.

Это прямо конфликтует с вашим требованием “2–3 рядом” и снижает надёжность.

### 3.2. Окклюзии и “люди стоят в дверях”

Одинарная линия и простая логика пересечения:

- чаще даёт **ложные IN/OUT**, если человек стоит/качается около линии;
- сложнее стабилизировать без доп. анти‑дублирования и “двух линий”.

### 3.3. Калибровка

Пример сильно зависит от:

- диапазона disparity (`threshold_low/high`);
- ядра морфологии (`kernel_size`);
- ROI и геометрии.

В транспорте (вибрации, разные двери, разные высоты) это означает, что придётся:

- делать строгий commissioning‑процесс,
- хранить набор профилей под разные геометрии,
- и всё равно останется риск “слипания” людей в один blob.

### 3.4. Где считается (нагрузка)

`DisparityToDetections` — **host‑детектор** (CPU на OPi), тогда как в нашем варианте:

- детектор/трекер/стерео — on‑device (OAK‑D),
- на host остаётся бизнес‑логика пересечений и (в debug) web‑UI.

Для слабого edge‑хоста это важная разница.

## 4) Что делает наш `transport-strict` (для сравнения)

Текущий контур проекта (door‑node):

- on-device: `DetectionNetwork (YOLOv6-nano person)` + `ObjectTracker(track_id)` + `StereoDepth`
- host: “2 линии + mid + anti‑duplicate + rearm + depth‑gate (head/shoulders)” + буферизация/протокол

Сильная сторона: **поддержка нескольких людей** зависит от качества детектора (bbox‑разделение), а не от depth‑blob.

Слабая сторона: при USB2 (`usb_speed=HIGH`) попытка поднять `FPS=15` усиливает `X_LINK_ERROR` → нужен упор на стабильность USB/питания и/или уменьшение потоков.

## 5) Сравнение (короткая таблица)

| Критерий | Luxonis `depth-people-counting` | Наш `transport-strict` |
|---|---|---|
| 2–3 человека рядом | Плохо (из коробки 1 контур; blob слипается) | Лучше (если детектор разделяет bbox) |
| “Стоят в дверях — не считать” | Сложно (1 линия, нет guard’ов) | Лучше (2 линии + cooldown/rearm + hang‑guard) |
| Настройка под разные двери | Сильная зависимость от порогов disparity/морфологии | Профили + геометрия линий + пороги детектора |
| Нагрузка на OPi | Host‑детектор (CPU) | Детектор/трекер/depth на камере; OPi в основном UI/логика |
| Privacy (без RGB) | Да, из коробки | Да (можно отключить preview/не хранить RGB; считать по событиям) |
| Масштабирование 100–200 систем | Нужна строгая стандартизация порогов/ROI | Уже заложена модульность профилей/commissioning |

## 6) Рекомендация под ваш проект

**Для подсчёта пассажиров IN/OUT в транспорте текущий `transport-strict` — правильная база.**

`depth-people-counting` можно рассматривать только как:

- исследовательский “privacy-only prototype” **для одиночного прохода**,
- или как источник идей для UI/визуализации disparity,
- но не как основной алгоритм под 2–3 человека рядом.

## 7) Что делать дальше (самый практичный план)

1. Зафиксировать “эталонный” профиль `transport-fast-pass` для двери (геометрия + пороги + crowd‑tuning трекера).
2. Собрать короткий датасет **реальной двери транспорта** (10–20 минут, разные сценарии: рядом/паровозиком/стоят).
3. Если основная проблема “2 рядом” = **1 bbox на двоих**:
   - заменить/усилить модель детектора (или входное разрешение),
   - либо обучить кастомную модель “top-down door person”.
4. Параллельно: аппаратная стабильность (USB‑кабель/питание), чтобы потом вернуться к `FPS=15` без `X_LINK_ERROR`.

## 8) Анализ предложенной схемы `CrowdHuman + YOLOv8 + StereoDepth` (2026-02-19)

Ниже оценка именно вашей предложенной реализации.

### Что в схеме корректно

- Использовать `Myriad X` и `blob` для OAK‑D Lite — корректно.
- Идея “голова/плечи + depth‑фильтр + track_id + crossing двух линий” — правильная для транспорта и сценария `2–3 рядом`.
- Перенос тяжёлой детекции/трекинга на камеру (а не на OPi) — правильный путь для стабильности edge‑узла.

### Что нужно поправить до внедрения

- `obj_id = det.label` неверно для подсчёта. `label` — это класс, а не уникальный ID объекта. Нужен `ObjectTracker` и `tracklets.id`.
- Фраза “industrial standard” — маркетинговая, не инженерный критерий. Нужна валидация на ваших сценариях проходов.
- Параметры `OpenVINO version / shaves` не универсальны “раз и навсегда”; подбирать по факту latency+stability на вашей прошивке/SDK.
- Критерий по `spatialCoordinates.y` зависит от системы координат; в проекте корректнее вести событие по пересечению линий в image-space и подтверждать depth отдельно.

### Оценка процента успеха

Оценка по двум уровням:

1) **Текущая рабочая реализация (stereo-only / transport-strict на стенде):**
- по зафиксированным прогонам `10+10` получено `~70–75%` полноты счёта (`14–15` из `20`).

2) **После перехода на head/head-shoulders модель уровня CrowdHuman + корректный tracker:**
- ожидаемый диапазон при той же геометрии и после калибровки: **`85–92%`**;
- для “2–3 рядом” потолок выше текущего именно за счёт лучшего разделения объектов.

### Вывод по внедрению

- Ваша идея технически верная и перспективнее текущего baseline для плотного потока.
- Реалистичный target на ближайший этап: поднять точность с текущих `~70–75%` до `>=85%` без роста ложных.
- Сначала внедряем head‑модель + `ObjectTracker(track_id)` + двухлинейный crossing, затем проводим серию одинаковых `10+10` тестов и фиксируем метрику.
